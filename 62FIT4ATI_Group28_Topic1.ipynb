{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# CELL 1: Setup + Load + Prepare\n",
        "# Mục đích:\n",
        "# 1) Nạp thư viện cần dùng (xử lý dữ liệu, baseline ML, DL PyTorch)\n",
        "# 2) Đọc data.csv vào df\n",
        "# 3) Chuẩn hoá nhãn theo phương pháp nhị phân: 0 -> 0, (1/2) -> 1 để thành bài toán nhị phân (0 là không bị tiểu đương, 1/2: có nguy cơ/bị tiểu đường)\n",
        "# 4) Tách X (21 feature) và y (label) để chuẩn bị train model\n",
        "# 5) In thống kê để kiểm tra dữ liệu đã đúng và thấy mức lệch lớp\n",
        "# =========================\n",
        "\n",
        "import os, numpy as np, pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Đọc dữ liệu\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "\n",
        "# Nhãn nhị phân (binary)\n",
        "y = (df[\"Diabetes_binary\"] > 0).astype(np.int64).values     # 0->0, 1/2->1\n",
        "X = df.drop(columns=[\"Diabetes_binary\"]).astype(np.float32).values  # 21 feature\n",
        "\n",
        "# Kiểm tra nhanh\n",
        "print(\"X shape:\", X.shape)  # (số mẫu, số feature)\n",
        "print(\"y distribution:\", dict(zip(*np.unique(y, return_counts=True))))  # xem lệch lớp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjAklzkAv2_u",
        "outputId": "8202bd2d-7a0a-4367-a855-b19b8fddc89b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (269131, 21)\n",
            "y distribution: {np.int64(0): np.int64(194377), np.int64(1): np.int64(74754)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# CELL 2: Split + Scale\n",
        "# Mục đích:\n",
        "# 1) Chia dữ liệu thành train/val/test để đánh giá công bằng (test không được nhìn lúc train)\n",
        "# 2) Dùng stratify để giữ đúng tỉ lệ lớp ở mọi tập (quan trọng vì dữ liệu lệch lớp)\n",
        "# 3) Chuẩn hoá feature bằng StandardScaler để model học ổn định (các cột về cùng thang đo)\n",
        "# 4) Lưu scaler để sau này inference/reproduce kết quả giống y chang\n",
        "# =========================\n",
        "\n",
        "# Chia train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Tách thêm validation từ train\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "# Scale: fit trên train, rồi transform val/test\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train).astype(np.float32)\n",
        "X_val_s   = scaler.transform(X_val).astype(np.float32)\n",
        "X_test_s  = scaler.transform(X_test).astype(np.float32)\n",
        "\n",
        "# Lưu scaler để tái sử dụng\n",
        "joblib.dump(scaler, \"scaler.joblib\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDxn_qjov56-",
        "outputId": "8427db05-f590-40d4-a209-b9daf663cd12"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# CELL 3: Baseline Logistic Regression\n",
        "# Mục đích:\n",
        "# 1) Train một mô hình đơn giản (Logistic Regression) làm \"baseline\"\n",
        "# 2) Baseline là mốc để chứng minh mô hình Deep Learning có cải thiện thật sự\n",
        "# 3) Đánh giá baseline bằng ROC-AUC + confusion matrix + classification report\n",
        "# 4) Lưu baseline model để nộp và reproduce\n",
        "# =========================\n",
        "\n",
        "lr = LogisticRegression(max_iter=2000, n_jobs=-1)\n",
        "lr.fit(X_train_s, y_train)\n",
        "\n",
        "# Dự đoán xác suất và nhãn\n",
        "proba_lr = lr.predict_proba(X_test_s)[:, 1]\n",
        "pred_lr  = (proba_lr >= 0.5).astype(int)\n",
        "\n",
        "# Đánh giá baseline\n",
        "print(\"=== Logistic Regression (Baseline) ===\")\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, proba_lr))\n",
        "print(confusion_matrix(y_test, pred_lr))\n",
        "print(classification_report(y_test, pred_lr, digits=4))\n",
        "\n",
        "# Lưu baseline\n",
        "joblib.dump(lr, \"logreg_baseline.joblib\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmeVwwUdwAZG",
        "outputId": "431faf58-3ed0-4843-9693-b8ca913cff78"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Logistic Regression (Baseline) ===\n",
            "ROC-AUC: 0.8046563272103694\n",
            "[[35307  3569]\n",
            " [ 8972  5979]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7974    0.9082    0.8492     38876\n",
            "           1     0.6262    0.3999    0.4881     14951\n",
            "\n",
            "    accuracy                         0.7670     53827\n",
            "   macro avg     0.7118    0.6541    0.6686     53827\n",
            "weighted avg     0.7498    0.7670    0.7489     53827\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['logreg_baseline.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# CELL 4: MLP Train (Deep Learning) + Optimization\n",
        "# Mục đích:\n",
        "# 1) Chuẩn bị DataLoader để train theo mini-batch (train nhanh và ổn định)\n",
        "# 2) Định nghĩa mô hình MLP (feedforward neural network) đúng yêu cầu đề bài\n",
        "# 3) Train model và áp dụng ít nhất 2 optimization techniques:\n",
        "#    - Optimization #1: pos_weight (xử lý lệch lớp)\n",
        "#    - Optimization #2: Dropout + Early stopping (giảm overfit, dừng đúng lúc)\n",
        "# 4) Lưu model train xong để nộp và tái chạy\n",
        "# =========================\n",
        "\n",
        "# --- DataLoader ---\n",
        "train_ds = TensorDataset(torch.tensor(X_train_s), torch.tensor(y_train).float())\n",
        "val_ds   = TensorDataset(torch.tensor(X_val_s),   torch.tensor(y_val).float())\n",
        "train_loader = DataLoader(train_ds, batch_size=1024, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=1024, shuffle=False)\n",
        "\n",
        "# --- MLP model ---\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 64), nn.ReLU(),\n",
        "            nn.Dropout(0.3),               # (Optimization) giảm overfit\n",
        "            nn.Linear(64, 32), nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(32, 1)               # output 1 logit (binary)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "model = MLP(X_train_s.shape[1])\n",
        "\n",
        "# --- Optimization #1: pos_weight để xử lý lệch lớp ---\n",
        "pos = y_train.sum()\n",
        "neg = len(y_train) - pos\n",
        "pos_weight = torch.tensor([neg / pos], dtype=torch.float32)\n",
        "\n",
        "# Loss + Optimizer (weight_decay = L2 regularization)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "# --- Optimization #2: Early stopping theo val AUC ---\n",
        "best_auc, patience, bad = -1.0, 5, 0\n",
        "best_state = None\n",
        "\n",
        "for epoch in range(30):\n",
        "    # Train\n",
        "    model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validate AUC\n",
        "    model.eval()\n",
        "    vp, vy = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            prob = torch.sigmoid(model(xb)).cpu().numpy()\n",
        "            vp.append(prob); vy.append(yb.cpu().numpy())\n",
        "\n",
        "    vp = np.concatenate(vp); vy = np.concatenate(vy)\n",
        "    auc = roc_auc_score(vy, vp)\n",
        "\n",
        "    print(f\"epoch {epoch+1:02d} | val_auc={auc:.4f}\")\n",
        "\n",
        "    # Early stopping: lưu best model\n",
        "    if auc > best_auc + 1e-4:\n",
        "        best_auc = auc\n",
        "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "        bad = 0\n",
        "    else:\n",
        "        bad += 1\n",
        "        if bad >= patience:\n",
        "            print(\"Early stopping.\")\n",
        "            break\n",
        "\n",
        "# Load model tốt nhất và lưu file model\n",
        "model.load_state_dict(best_state)\n",
        "torch.save(model.state_dict(), \"mlp_model.pt\")\n",
        "print(\"Saved: mlp_model.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLKulhTpwC7c",
        "outputId": "5e8c0f49-da66-44a4-a0c6-e7bc5808f4cc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 01 | val_auc=0.8023\n",
            "epoch 02 | val_auc=0.8049\n",
            "epoch 03 | val_auc=0.8057\n",
            "epoch 04 | val_auc=0.8063\n",
            "epoch 05 | val_auc=0.8066\n",
            "epoch 06 | val_auc=0.8066\n",
            "epoch 07 | val_auc=0.8069\n",
            "epoch 08 | val_auc=0.8069\n",
            "epoch 09 | val_auc=0.8070\n",
            "epoch 10 | val_auc=0.8071\n",
            "epoch 11 | val_auc=0.8072\n",
            "epoch 12 | val_auc=0.8071\n",
            "epoch 13 | val_auc=0.8073\n",
            "epoch 14 | val_auc=0.8072\n",
            "epoch 15 | val_auc=0.8073\n",
            "epoch 16 | val_auc=0.8073\n",
            "epoch 17 | val_auc=0.8074\n",
            "epoch 18 | val_auc=0.8076\n",
            "epoch 19 | val_auc=0.8077\n",
            "epoch 20 | val_auc=0.8076\n",
            "epoch 21 | val_auc=0.8077\n",
            "epoch 22 | val_auc=0.8078\n",
            "epoch 23 | val_auc=0.8077\n",
            "epoch 24 | val_auc=0.8076\n",
            "epoch 25 | val_auc=0.8078\n",
            "epoch 26 | val_auc=0.8076\n",
            "Early stopping.\n",
            "Saved: mlp_model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# CELL 5: Evaluate + Inference\n",
        "# Mục đích:\n",
        "# 1) Đánh giá mô hình MLP trên test set (phần dữ liệu chưa thấy khi train)\n",
        "# 2) In ROC-AUC + confusion matrix + report để so sánh với baseline\n",
        "# 3) Demo inference: nhập 1 mẫu mới -> scale -> model trả xác suất nguy cơ\n",
        "# =========================\n",
        "\n",
        "# --- Test evaluation ---\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    prob_mlp = torch.sigmoid(model(torch.tensor(X_test_s))).cpu().numpy()\n",
        "\n",
        "pred_mlp = (prob_mlp >= 0.5).astype(int)\n",
        "\n",
        "print(\"=== MLP (Optimized) ===\")\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, prob_mlp))\n",
        "print(confusion_matrix(y_test, pred_mlp))\n",
        "print(classification_report(y_test, pred_mlp, digits=4))\n",
        "\n",
        "# --- Inference demo (1 sample) ---\n",
        "x_new = X_test[:1].astype(np.float32)                 # giả lập 1 người mới\n",
        "x_new_s = scaler.transform(x_new).astype(np.float32)  # scale giống lúc train\n",
        "\n",
        "with torch.no_grad():\n",
        "    p = torch.sigmoid(model(torch.tensor(x_new_s))).item()\n",
        "\n",
        "print(\"Predicted diabetes risk probability:\", p)\n",
        "print(\"Predicted class:\", int(p >= 0.5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZYB4CEHwHmq",
        "outputId": "535f0a5f-2580-4b88-b7a7-2902ff7393f4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== MLP (Optimized) ===\n",
            "ROC-AUC: 0.8137359530242804\n",
            "[[26669 12207]\n",
            " [ 3173 11778]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8937    0.6860    0.7762     38876\n",
            "           1     0.4911    0.7878    0.6050     14951\n",
            "\n",
            "    accuracy                         0.7143     53827\n",
            "   macro avg     0.6924    0.7369    0.6906     53827\n",
            "weighted avg     0.7818    0.7143    0.7286     53827\n",
            "\n",
            "Predicted diabetes risk probability: 0.1568731963634491\n",
            "Predicted class: 0\n"
          ]
        }
      ]
    }
  ]
}